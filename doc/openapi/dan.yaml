openapi: 3.1.0
info:
  title: DAN API
  description: >-
    ## Conventions


    The base URL to send all API requests is

    ```

    https://api.opendan.ai

    ```


    HTTPS is required for all API requests.


    The DAN API follows RESTful conventions when possible, with most operations
    performed via GET, POST, PATCH, and DELETE requests on page and database
    resources. Request and response bodies are encoded as JSON.


    At present, only HTTP requests are supported to complete image generation
    tasks.


    The APIs has similar respones.


    On success, dan server will response http `status code` 200 and an object in
    JSON as below:


    ```JSON

    {
        "code": 200,
        "data": `The returned object`,
        "message": "success"
    }

    ```


    On failure, dan server will response a non-ok http `status code` (i.e. not
    200, may be 401 for an example) and an object JSON as below:


    ```JSON

    {
        "code": `Error code`,
        "message": `A string describe the error`
    }

    ```


    ## Supported list values

    Under rapid expansion, please stay tuned.


    ### Models

    | Name                 |
    Value                                                            |
    Ref                                                                |
    Download                                                                                                        
    |

    | -------------------- |
    ---------------------------------------------------------------- |
    ------------------------------------------------------------------ |
    ----------------------------------------------------------------------------------------------------------------
    |

    | chillout_mix         |
    3a17d0deffa4592fd91c711a798031a258ab44041809ade8b4591c0225ea9401 | [link to
    civitai](https://civitai.com/models/6424/chilloutmix)     |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors)
    |

    | clarity              |
    627a6f5c8bf7669d4a224ac041d527debc65d2d435b16e54ead8ee2c901d1634 | [link to
    civitai](https://civitai.com/models/5062/clarity)         |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/clarity.safetensors)                    
    |

    | anything-v4.5-pruned |
    6e430eb51421ce5bf18f04e2dbe90b2cad437311948be4ef8c33658a73c86b2a | [link to
    huggingface](https://huggingface.co/andite/anything-v4.0) |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/anything-v4.5-pruned.safetensors)       
    |




    ### LoRas


    | Name                               |
    Value                                                            |
    Ref                                                                                   
    |
    Download                                                                                                               
    |

    | ---------------------------------- |
    ---------------------------------------------------------------- |
    --------------------------------------------------------------------------------------
    |
    -----------------------------------------------------------------------------------------------------------------------
    |

    | koreanDollLikeness_v10             |
    62efe75048d55a096a238c6e8c4e12d61b36bf59e388a90589335f750923954c | [link to
    civitai](https://civitai.com/models/19356/koreandolllikenessv10)             
    |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/koreandolllikeness_V10.safetensors)            
    |

    | stLouisLuxuriousWheels_v1          |
    f1efd7b748634120b70343bc3c3b425c06c51548431a1264a2fcb5368352349f | [link to
    civitai](https://civitai.com/models/6669/st-louis-luxurious-wheels-azur-lane)
    |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/stLouisLuxuriousWheels_v1.safetensors)         
    |

    | taiwanDollLikeness_v10             |
    5bbaabc04553d5821a3a45e4de5a02b2e66ecb00da677dd8ae862efd8ba59050 | [link to
    civitai](https://civitai.com/models/17497/taiwan-doll-likeness)              
    |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/taiwanDollLikeness_v10.safetensors)            
    |

    | kobeni_v10                         |
    3e5d8fe726b4c0f1e7f0905f32ea3d1c9ce89a54028209e8179d64d323048dac | [link to
    civitai](https://civitai.com/models/6679/kobeni)                             
    |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/kobeni_v10.safetensors)                        
    |

    | thickerLinesAnimeStyle_loraVersion |
    759d6fdf539f44f6991efd27ef1767c7779ac8884defc71dd909e5808b5ea74b | [link to
    civitai](https://civitai.com/models/13910/thicker-lines-anime-style-lora-mix)
    |
    [download](https://huggingface.co/fiatrete/dan-used-models/resolve/main/thickerLinesAnimeStyle_loraVersion.safetensors)
    |




    ### Samplers

    - DPM++ SDE Karras

    - Euler a

    - Euler

    - DPM++ SDE

    - LMS

    - DDIM
  version: 1.0.0
tags:
  - name: Stable Diffusion API
security:
  - BearerAuth: []
components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      description: >-
    
        - Bearer DAN_API_KEY.

        - Public anonymous DAN_API_KEY is:

        ```

        sk-000000000000000000000000000000000000000000000000

        ```

        - Please refer to the [Authentication section](../Authentication.mdx) on how to obtain a private DAN_API_KEY.
  schemas: {}
  x-common-parameter-content-type: &common_parameters_content_type
    name: Content-Type
    in: header
    description: application/json is required
    required: true
    example: application/json
    schema:
      type: string
  x-common-parameters-authorization: &common_parameters_authorization
    name: Authorization
    in: header
    description: >-
    
        - Bearer DAN_API_KEY.

        - Public anonymous DAN_API_KEY is:

        ```

        sk-000000000000000000000000000000000000000000000000

        ```

        - Please refer to the [Authentication section](../Authentication.mdx) on how to obtain a private DAN_API_KEY.


    required: true
    example: Bearer sk-000000000000000000000000000000000000000000000000
    schema:
      type: string
  x-common-parameters-accept: &common_parameters_accept
    name: Accept
    in: header
    description: ''
    required: false
    example: application/json
    schema:
      type: string
  x-common-parameters-basics: &common_parameters_basics
    - *common_parameters_authorization
    - *common_parameters_content_type
    - *common_parameters_accept
  x-common-xxx2img-parameters: &common_xxx2img_properties
    prompt:
      type: string
      description: >-
        A positive prompt that describes what you want the image to
        be.
    sampler_name:
      type: string
      description: >-
        The name of the sampling algorithm used. refer to the
        `Introduction section` for supported list values
    model:
      type: string
      description: >-
        The model used to generate the image. refer to the
        `Introduction section` for supported list values
    width:
      type: integer
      description: >-
        The desired width of the resulting image. Valid range is
        [8, 1024]. 
    height:
      type: integer
      description: >-
        The desired height of the resulting image. Valid range is
        [8, 1024].
    loras:
      type: array
      items:
        type: array
        items:
          type: string
          description: >-
            LoRAs value and weight . For example, fill in
            ["62efe75048d55a096a238c6e8c4e12d61b36bf59e388a90589335f750923954c",
            0.7]
        description: LoRAs list
      description: >-
        - A list of LoRAs to be applied and their weights. 

        - Format example

        ``` 

        [        
            ["XXXXXXXX", 0.5],        
            ["XXXXXXXX", 0.6]
        ]

        ```

        - "XXXX" mean LoRA value. Such like
        "62efe75048d55a096a238c6e8c4e12d61b36bf59e388a90589335f750923954c". 

        - Refer to the Introduction section for supported list
        values. 
    seed:
      type: integer
      description: '-1 for a random seed.'
    steps:
      type: integer
      description: Number of inference steps. Valid range is [20, 60], default 20.
    cfg_scale:
      type: integer
      description: >-
        A classifier-free guidance scale; smaller values result in higher quality images, and larger
        values yield images closer to the provided prompt. Valid range is [1, 30].
    negative_prompt:
      type: string
      description: >-
        A negative prompt that describes what you don't want in the image.
    control_net:
      type: array
      items:
        type: object
        properties:
          image:
            type: string
            description: The reference image file, encoded in base64
          model:
            type: string
            description: >-
              The control net model. Valid options are: `sd15_canny` and `sd15_openpose`.
          preprocess:
            type: string
            description: >-
              How the reference image should be preprocessed, you can specify the preprocess method name. Valid options are: `canny` and `openopse`.
          preprocess_param1:
            type: unknown
            description: |
              Optional. Some control net model (e.g. sd15_canny) requires parameters, this is the first parameter.
              See the table below. If you don't known what to fill in here, just leave it undefined.

              <table>
                <tr>
                  <th>Control net model</th>
                  <th>Type</th>
                  <th>Description</th>
                </tr>
                <tr>
                  <td>sd15_canny</td>
                  <td>number</td>
                  <td>The first threshold of canny algorithm. For more information, see <a a target="_blank" href="https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html">opencv doc</a></td>
                </tr>
                <tr>
                  <td>sd15_openpose</td>
                  <td>Ignored</td>
                  <td>Ignored</td>
                </tr>
              </table>
          preprocess_param2:
            type: unknown
            description: |
              Optional. Some control net model (e.g. sd15_canny) requires parameters, this is the second parameter.
              See the table below. If you don't known what to fill in here, just leave it undefined.

              <table>
                <tr>
                  <th>Control net model</th>
                  <th>Type</th>
                  <th>Description</th>
                </tr>
                <tr>
                  <td>sd15_canny</td>
                  <td>number</td>
                  <td>The second threshold of canny algorithm. For more information, see <a target="_blank" href="https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html">opencv doc</a></td>
                </tr>
                <tr>
                  <td>sd15_openpose</td>
                  <td>Ignored</td>
                  <td>Ignored</td>
                </tr>
              </table>
          weight:
            type: number
            description: >-
              Before merging control net into the main SD model, all weights will be scaled by this value. Valid range is [0, 2], default value is 1.
          resize_mode:
            type: number
            description: >-
              If control image's dimension does not equal to target dimension, stable diffusion will resize the control image.
              0 means just resize, 1 means resize and crop, 2 means resize and fill, otherwise use default value: 0.
          guidance_start:
            type: number
            description: >-
              The control net will be applied in [guidance_start, guidance_end] percents inference steps. Valid range is [0, 1], default: 0.
          guidance_end:
            type: number
            description: >-
              The control net will be applied in [guidance_start, guidance_end] percents inference steps. Valid range is [0, 1], default: 1.
          guessmode:
            type: bool
            description: >-
              Optional. Default: false.
              If true, you can just remove all prompts, and then the control net encoder will recognize the content of the input control map.
              For this mode, we recommend to use 50 steps and guidance scale between 3 and 5.
        required:
          - image
          - preprocess
          - model
      description: >-
        Optional. An array of control net parameters. Theoretically speaking, multiple control net can be applied simultaneously,
        but currently only up to 1 control net is supported, if you specify more than 1 set of paramters, the rest (i.e. not the first one)
        will be ignored.
  x-common-xxx2img-200-content: &common_xxx2img_200
    content:
      application/json:
        schema:
          type: object
          properties:
            code:
              type: integer
            data:
              type: object
              properties:
                images:
                  type: array
                  items:
                    type: string
                  description: >-
                    string of base 64 encoded png file. When status = 2, a
                    list of images is returned
                taskId:
                  type: string
                queuePosition:
                  type: integer
                  description: >-
                    The length of the queue of pending tasks. When status
                    != 0, queuePosition = 0
                status:
                  type: integer
                  description: 0:pending, 1:processing, 2:success, 3:fail
              required:
                - taskId
                - queuePosition
                - status
                - images
            message:
              type: string
          required:
            - code
            - data
            - message
        examples:
          Success:
            summary: Success
            value:
              code: 200
              data:
                taskId: 60a4755e-ceb3-4172-8760-28ce47acf04d
                queuePosition: 0
                status: 2
                images:
                  - >-
                    iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAAxHRFWHRwYXJhbWV0ZXJzAEEgY2F0LDxsb3JhOmtvcmVhbkRvbGxMaWtlbmVzc192MTA6MC43PgpTdGVwczogMjAsIFNhbXBsZXI6IERESU0sIENGRyBzY2FsZTogNy4wLCBTZWVkOiAxNjQ4MDc1MzQ1LCBTaXplOiAxNngxNiwgTW9kZWwgaGFzaDogM2ExN2QwZGVmZiwgU2VlZCByZXNpemUgZnJvbTogLTF4LTEsIERlbm9pc2luZyBzdHJlbmd0aDogMC41x0iUTgAAAjhJREFUeJwFwcluE0EUBdD7Xo3tbtuJTQggISGQ2OcD2PC/fAIrtggigRALBjEmxEkc91zdVfU4h77sfvv1idLWTFAKf/5ebLabdekEMAADGpiRGRyQh3pPQXIbySpwRghom4P3yvgFG67rZmoPq6pYVJXXjgEAmkAgZAIUMrBaGkojRWHylaLBGauN14ohgABMQeQQsrNcdzmO4d4SlQHYAwQAiEACHIAR8IDusoR5bJp0aPpC67yswA4QAAAm6DHrERDG7wB20MM8d9Ow3zcxz2W1gVMTcsB82fQfv1zc1V3bmY5N8tWfy10XDnQrcru/TcRF6bfGA7gJ/fuv31+9Pn/z9vM0hvXJ1vo15nLup+uw0wrw3h0XJQMMZCDbxdef4cP51dgZX9j7m9Xp/e3Nv+iPjs9OnusYkafU5F5SWlUlMccRK+/Onj12y8XLF2dPnywfHlW7u9Ea/6QEdSJ3+zqGZJ09rgpjuBNc37UyTKenGyMxY2ZWSmxkOAINIn03O6utIQlRkcAoAnhOwgDpRALJac7OWjB0AoxTVlPMEMEo0ZFSYLE0A5IJREJC1gSIA+kJaIYhBXHFYl1qBd0DCrAgSdkLEWUoylmyYgA8BMmksiNTsgAR2Nft39113baFYtIxNbfh5w9WrAEA9K3pCDGF0EftF8XlxdUwhG4aHp2sXeZw0/Z9PNquLpqAYrVZK/3v8mr74JQUAzjMGHmBwoV+uK47mdLNr52262YR3336pIuyRPgPgVo9viLutFEAAAAASUVORK5CYII=
              message: success
  x-common-interrogate-200-content: &common_interrogate_200
    content:
      application/json:
        schema:
          type: object
          properties:
            code:
              type: integer
            data:
              type: object
              properties:
                caption:
                  type: string
                  description: The input image description
                taskId:
                  type: string
                queuePosition:
                  type: integer
                  description: >-
                    The length of the queue of pending tasks, when status
                    != 0, queuePosition = 0
                status:
                  type: integer
                  description: 0:pending, 1:processing, 2:success, 3:fail
              required:
                - taskId
                - queuePosition
                - status
                - caption
            message:
              type: string
          required:
            - code
            - data
            - message
        examples:
          Success:
            summary: Success
            value:
              code: 200
              data:
                taskId: faa37545-b284-461d-85fc-32468c7af036
                queuePosition: 0
                status: 2
                caption: >-
                  a blurry image of a white and blue background with a
                  blurry effect of a blue and white background, Carlos
                  Trillo Name, behance hd, a detailed matte painting, net
                  art
              message: success
  x-common-async-200-content: &common_async_200
    content:
      application/json:
        schema:
          type: object
          properties:
            code:
              type: integer
            data:
              type: object
              properties:
                taskId:
                  type: string
                queuePosition:
                  type: integer
                  description: >-
                    The length of the queue of pending tasks, when status
                    != 0, queuePosition = 0
                status:
                  type: integer
                  description: 0:pending, 1:processing, 2:success, 3:fail
              required:
                - taskId
                - queuePosition
                - status
            message:
              type: string
          required:
            - code
            - data
            - message
        examples:
          Success:
            summary: Success
            value:
              code: 200
              data:
                taskId: 00ac7e02-bff0-4741-8798-0cd7821dedf7
                queuePosition: 0
                status: 2
              message: success
paths:
  /api/sd/txt2img:
    post: &txt2img_post
      summary: /api/sd/txt2img
      deprecated: false
      description: This interface provides a service for generating images from text.
      tags:
        - Stable Diffusion API
      parameters: *common_parameters_basics
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                <<: *common_xxx2img_properties
                upscale:
                  type: object
                  properties:
                    denoising_strength:
                      type: number
                      description: >-
                        Controls the level of denoising; smaller values yield
                        results that are closer to the original generated image,
                        but may be blurry; larger values may lead the output
                        looks different from the original generated image and
                        may looks strange. Valid range is [0, 1], but I
                        recomment you make it between 0.4 and 0.6.
                    scale:
                      type: number
                      description: The upscale rate. Valid range is (1.0, 2.0].
                    upscaler:
                      type: string
                      description: >-
                        The upscaler algorithm name, Currently only Latent is
                        supported.
                  description: Optional, add it if you want to upscale the result.
              required:
                - prompt
                - sampler_name
                - width
                - height
                - model
            example:
              prompt: A cat
              sampler_name: DDIM
              width: 512
              height: 512
              model: 3a17d0deffa4592fd91c711a798031a258ab44041809ade8b4591c0225ea9401
              cfg_scale: 7
              negative_prompt: ''
              seed: -1
              loras:
                - - >-
                    62efe75048d55a096a238c6e8c4e12d61b36bf59e388a90589335f750923954c
                  - 0.7
              steps: 20
              upscale:
                denoising_strength: 0.5
                scale: 2
                upscaler: Latent
      responses:
        '200':
          <<: *common_xxx2img_200
          description: The generated image is returned here.
  /api/sd/txt2img/async:
    post:
      <<: *txt2img_post
      summary: /api/sd/txt2img/async
      description: >-
        This interface provides a service for generating images from text. <br/>
        Its usage is almost the same as `txt2img`. The difference between this interface and `txt2img` is that this interface will return immediately with task information.<br/>
        After obtaining the task information, you can use the [`/api/sd/task/status`](./api-sd-task-status.api.mdx) interface to query the task status and get the result.
      responses:
        '200':
          <<: *common_async_200
          description: Instead of returning the final result, this API returns the `taskId` and `queueing information`. You can use [`/api/sd/task/status`](./api-sd-task-status.api.mdx) to query the latest status of the task or get the final result.
  /api/sd/img2img:
    post: &img2img_post
      summary: /api/sd/img2img
      deprecated: false
      description: This interface provides a service for generating images from images.
      tags:
        - Stable Diffusion API
      parameters: *common_parameters_basics
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                init_image:
                  type: string
                  description: The base64-encoded string of your original image
                denoising_strength:
                  type: number
                  description: "Controls the level of denoising; smaller values yield results that are closer to the original image. Valid range is [0, 1]"
                <<: *common_xxx2img_properties
                inpaint:
                  type: object
                  description: If you want to regenerate part of your image, this will be what you want.
                  properties:
                    mask:
                      type: string
                      description: This is a base64 encoded image of a mask which defined where you want to regenerate.
                    mask_blur:
                      type: number
                      description: Before regenerating, the image and mask will be gaussian blured by this radius. Valid range is [0, 64], default 0.
                    mask_mode:
                      type: number
                      description: 0 means regenerate where is masked; 1 means regenerate where is not masked.
                    inpaint_area:
                      type: number
                      description: 0 means regenerate whole image, then paste corresponding area back. 1 means only the masked area will be regenereate, then paste corresponding area back.
                  required:
                    - mask
              required:
                - prompt
                - sampler_name
                - width
                - height
                - denoising_strength
                - init_image
                - model
            example:
              prompt: A cat
              loras:
                - - >-
                    62efe75048d55a096a238c6e8c4e12d61b36bf59e388a90589335f750923954c
                  - 0.7
              seed: -1
              sampler_name: DDIM
              steps: 20
              cfg_scale: 7
              width: 512
              height: 512
              negative_prompt: ''
              model: 3a17d0deffa4592fd91c711a798031a258ab44041809ade8b4591c0225ea9401
              denoising_strength: 0.5
              init_image: >-
                iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAAwnRFWHRwYXJhbWV0ZXJzAEEgY2F0LDxsb3JhOmtvcmVhbkRvbGxMaWtlbmVzc192MTA6MC43PgpTdGVwczogMjAsIFNhbXBsZXI6IERESU0sIENGRyBzY2FsZTogNy4wLCBTZWVkOiAyMzAwMjY4MzQwLCBTaXplOiAxNngxNiwgTW9kZWwgaGFzaDogM2ExN2QwZGVmZiwgU2VlZCByZXNpemUgZnJvbTogLTF4LTEsIERlbm9pc2luZyBzdHJlbmd0aDogMOLvrY0AAAEWSURBVHicjZHBTkJBDEXPbWdAg4n+/3f5GSYuJIHHTFsXiKCCelYzyT1Nc6vXl+eHxyf3jbSGOxAfFAjy9E5ImKp6hQ4bvpNUIIGBoGAP3qCBIMC/Cobs4itYQzYA4sf4qzi4zf12LDs4/M+hbbc7804u/a6j9qdgy4hlHHIG85fFCgom0B42jyOGrNOvjv+MjmPLqqocb9ZWaH0Rmqfuj0JAgkCqKhjQT+mMHElkDbOJQqQhqMQER+HM5DBy5NxLU8yoxSy94Qgs4PI0H9vI0pzKOcahakQskXuRgE6HO9NZdQjX9KyxyAvMDMeg143iVw5OWU9wIyGgQYnVrSoFYaTokAbJLEy0q4Kgw71jYJAQRsAWeAf79pJ7zSui0wAAAABJRU5ErkJggg==
      responses:
        '200':
          <<: *common_xxx2img_200
          description: The generated image is returned here.
  /api/sd/img2img/async:
    post:
      <<: *img2img_post
      summary: /api/sd/img2img/async
      description: >-
        This interface provides a service for generating images from images. <br/>
        Its usage is almost the same as `img2img`. The difference between this interface and `img2img` is that this interface will return immediately with task information.<br/>
        After obtaining the task information, you can use the [`/api/sd/task/status`](./api-sd-task-status.api.mdx) interface to query the task status and get the result.
      responses:
        '200':
          <<: *common_async_200
          description: Instead of returning the final result, this API returns the `taskId` and `queueing information`. You can use [`/api/sd/task/status`](./api-sd-task-status.api.mdx) to query the latest status of the task or get the final result.
  /api/sd/interrogate:
    post: &interrogate_post
      summary: /api/sd/interrogate
      deprecated: false
      description: 'Interrogate tasks will generate a description for an input image. '
      tags:
        - Stable Diffusion API
      parameters: *common_parameters_basics
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                image:
                  type: string
                  description: The base64-encoded string of your input image
                model:
                  type: string
                  description: >-
                    The model name used to describe the image, avalaible options
                    are clip and deepdanbooru
              required:
                - image
                - model
            example:
              image: >-
                iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAAwnRFWHRwYXJhbWV0ZXJzAEEgY2F0LDxsb3JhOmtvcmVhbkRvbGxMaWtlbmVzc192MTA6MC43PgpTdGVwczogMjAsIFNhbXBsZXI6IERESU0sIENGRyBzY2FsZTogNy4wLCBTZWVkOiAyMzAwMjY4MzQwLCBTaXplOiAxNngxNiwgTW9kZWwgaGFzaDogM2ExN2QwZGVmZiwgU2VlZCByZXNpemUgZnJvbTogLTF4LTEsIERlbm9pc2luZyBzdHJlbmd0aDogMOLvrY0AAAEWSURBVHicjZHBTkJBDEXPbWdAg4n+/3f5GSYuJIHHTFsXiKCCelYzyT1Nc6vXl+eHxyf3jbSGOxAfFAjy9E5ImKp6hQ4bvpNUIIGBoGAP3qCBIMC/Cobs4itYQzYA4sf4qzi4zf12LDs4/M+hbbc7804u/a6j9qdgy4hlHHIG85fFCgom0B42jyOGrNOvjv+MjmPLqqocb9ZWaH0Rmqfuj0JAgkCqKhjQT+mMHElkDbOJQqQhqMQER+HM5DBy5NxLU8yoxSy94Qgs4PI0H9vI0pzKOcahakQskXuRgE6HO9NZdQjX9KyxyAvMDMeg143iVw5OWU9wIyGgQYnVrSoFYaTokAbJLEy0q4Kgw71jYJAQRsAWeAf79pJ7zSui0wAAAABJRU5ErkJggg==
              model: clip
      responses:
        '200':
          <<: *common_interrogate_200
          description: The input image's description is returned here.
  /api/sd/interrogate/async:
    post:
      <<: *interrogate_post
      summary: /api/sd/interrogate/async
      deprecated: false
      description: >-
        Interrogate tasks will generate a description for an input image.<br/>
        Its usage is almost the same as `interrogate`. The difference between this interface and `interrogate` is that this interface will return immediately with task information.<br/>
        After obtaining the task information, you can use the [`/api/sd/task/status`](./api-sd-task-status.api.mdx) interface to query the task status and get the result.
      tags:
        - Stable Diffusion API
      responses:
        '200':
          <<: *common_async_200
          description: Instead of returning the final result, this API returns the `taskId` and `queueing information`. You can use [`/api/sd/task/status`](./api-sd-task-status.api.mdx) to query the latest status of the task or get the final result.
  /api/sd/task/status:
    post:
      summary: /api/sd/task/status
      deprecated: false
      description: This API is used to query task's progress or retrive the task's result.
      tags:
        - Task
      parameters: *common_parameters_basics
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                taskId:
                  type: string
                  description: The task id returned by asynchronous API, which is the task you care about.
              required:
                - taskId
            example:
              image: >-
                iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAAwnRFWHRwYXJhbWV0ZXJzAEEgY2F0LDxsb3JhOmtvcmVhbkRvbGxMaWtlbmVzc192MTA6MC43PgpTdGVwczogMjAsIFNhbXBsZXI6IERESU0sIENGRyBzY2FsZTogNy4wLCBTZWVkOiAyMzAwMjY4MzQwLCBTaXplOiAxNngxNiwgTW9kZWwgaGFzaDogM2ExN2QwZGVmZiwgU2VlZCByZXNpemUgZnJvbTogLTF4LTEsIERlbm9pc2luZyBzdHJlbmd0aDogMOLvrY0AAAEWSURBVHicjZHBTkJBDEXPbWdAg4n+/3f5GSYuJIHHTFsXiKCCelYzyT1Nc6vXl+eHxyf3jbSGOxAfFAjy9E5ImKp6hQ4bvpNUIIGBoGAP3qCBIMC/Cobs4itYQzYA4sf4qzi4zf12LDs4/M+hbbc7804u/a6j9qdgy4hlHHIG85fFCgom0B42jyOGrNOvjv+MjmPLqqocb9ZWaH0Rmqfuj0JAgkCqKhjQT+mMHElkDbOJQqQhqMQER+HM5DBy5NxLU8yoxSy94Qgs4PI0H9vI0pzKOcahakQskXuRgE6HO9NZdQjX9KyxyAvMDMeg143iVw5OWU9wIyGgQYnVrSoFYaTokAbJLEy0q4Kgw71jYJAQRsAWeAf79pJ7zSui0wAAAABJRU5ErkJggg==
              model: clip
      responses:
        '200':
          content:
            application/json:
              schema:
                type: object
                properties:
                  code:
                    type: integer
                  data:
                    type: object
                    properties:
                      caption:
                        type: string
                        description: Maybe `undefined`. If the task a an interrogate task, This is the input image description.
                      images:
                        type: array
                        items:
                          type: string
                        description: >-
                          May be `undefined`. If the task is txt2img/img2img task, this is the generated file list, encoded in base64.
                      taskId:
                        type: string
                      queuePosition:
                        type: integer
                        description: >-
                          The length of the queue of pending tasks, when status
                          != 0, queuePosition = 0
                      status:
                        type: integer
                        description: 0:pending, 1:processing, 2:success, 3:fail
                    required:
                      - taskId
                      - queuePosition
                      - status
                  message:
                    type: string
                required:
                  - code
                  - data
                  - message
              examples:
                Success:
                  summary: Success
                  value:
                    code: 200
                    data:
                      taskId: faa37545-b284-461d-85fc-32468c7af036
                      queuePosition: 0
                      status: 2
                      caption: >-
                        a blurry image of a white and blue background with a
                        blurry effect of a blue and white background, Carlos
                        Trillo Name, behance hd, a detailed matte painting, net
                        art
                    message: success
          description: >-
            If the task has not been finished, only the task information is returned.
            Else return the task output.
servers:
  - url: https://api.opendan.ai
    description: release
